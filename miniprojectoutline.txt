# -*- coding: utf-8 -*-
"""MiniProjectOutline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16mrvLm934DYtQcoY_qjYuyulUkgPQtbY

# **ENGR 100, Fall 2025, Mini Project**

**Team Members:**

**The intent of this document is to give you a starting point of the overall outline of tasks, and a few functions so that you can generate the required information for the demo.**

First upload the images to colab.
"""

from google.colab import files
from IPython.display import Image
uploaded = files.upload()

"""View the images in your current working directory. This will verify you have access to the images you just uploaded."""

!ls # accesses the current working directory

"""Generate a list of your file names. We will use a built-in Python module called "glob" to do this efficiently."""

import glob

image_files = glob.glob('*.jpg') # extracts all .jpg files from your working directory
print(image_files) # print and verify all your files are in the list

"""We download and install the CLIP embedding model."""

# Install required libraries (run this in Google Colab)
!pip install transformers torchvision pillow

# Import necessary modules
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import torch
import numpy as np

# Load the CLIP model and processor
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

def image_embedding(image_path):
    """
    Takes an image file path and returns its embedding as a NumPy array.
    """
    # Load and preprocess the image
    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt")

    # Extract image features
    with torch.no_grad():
        embeddings = model.get_image_features(**inputs)

    # Normalize and convert to NumPy
    embeddings = embeddings / embeddings.norm(p=2, dim=-1, keepdim=True)
    return embeddings.squeeze().cpu().numpy()

# Example usage:
# embedding = image_embedding("your_image.jpg")
# print("Embedding shape:", embedding.shape)

"""Code below is to downlad an image from the web and save it in Google Colab."""

import requests
from PIL import Image
from io import BytesIO

def download_image_from_url(url, save_as="downloaded_image.jpg"):
    """
    Downloads an image from a URL and saves it locally in Colab.
    Returns the local filename.
    """
    response = requests.get(url)
    response.raise_for_status()  # Raise error for bad status
    image = Image.open(BytesIO(response.content)).convert("RGB")
    image.save(save_as)
    return save_as

"""Download an image from web and test that embedding code works as intended and returns a numpy array."""

# Example usage:
image_url = "https://umich.edu/skins/um2013/media/images/U-M-logo-preview.jpg"
filename = download_image_from_url(image_url)
print("Image saved as:", filename)
embedding = image_embedding(filename)
print("Embedding shape:", embedding.shape)

embedding # outputs the numbers

"""Create an embedding matrix of the images that you uploaded."""

# What functions did you use in pathbird to create an embedding matrix?
# Make sure to define them here. You will also have to use embedding model

embedding_matrix = ??

"""Use two test images from the web to test that the embedding matrix returns what you expect."""

test_embedding_matrix = ??

"""Once you have the embedding matrix, you can generate the cosine similarity matrix.

I have defined a function to use for this below.
"""

def compute_cosine_similarity_matrix(embedding_matrix): #

# fill in your code  here
# inportant: what dimensions should similarity matrix be?
# what should diagonals of matrix be?
# check your predictions on np.random.randn(10,5) as input
# assuming embedding vectors are stacked row wise
  return cosine_similarity_matrix

"""Again, use test images from the web to verify your code works as planned."""

test_similarity_matrix = ??

"""Then, you can generate the matrix for your images."""

cosine_similarity_matrix = ??

"""Now, you can generate a heatmap, which will visualize the results of the cosine similarity calculations.

The function to generate this is defined below.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

def heatmap_cosine_similarities(cosine_similarity_matrix, threshold, labels):
  mask = cosine_similarity_matrix < threshold

  plt.figure(figsize=(12, 10))

  sns.heatmap(
      cosine_similarity_matrix,
      xticklabels=labels,
      yticklabels=labels,
      annot=True,
      fmt=".2f",
      cmap="coolwarm",
      square=True,
      cbar=True,
      mask=mask  # Hide values below threshold
  )

  plt.title(f"Cosine Similarity Heatmap (Threshold = {threshold})")
  plt.xticks(rotation=45, ha='right')
  plt.yticks(rotation=0)
  plt.tight_layout()
  plt.show()

# use a command here to display your heatmap with appropriate labels
# the threshold value can be between 0.0 and 1.0
# adjust the threshold to help you visually compare images

"""After evaluating these results, we want to downsample, and display the heatmap for only **some** of these images.

In a future codex, you will learn about tools for data visualization, and what good practices will look like.

Make sure to discuss as a team which images you'd like to select for this final heatmap.

# **Generating the Final Heatmap**

Using similar logic to the previous code, think about how to select only **some** images from your dataset.

The comments below help give you an idea of the steps to take, and as a team, you will fill it out together to generate your final result.
"""

# generate a list of your selected images

# create a new embedding matrix

# generate the cosine similarity matrix

# display your new heatmap

"""# **Test Your Hypothesis**
After gathering additional images, use these to generate a new heatmap so you can observe any changes in your results.
"""

# write your own code here!